{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Titanic Classification** : a Predictive Model to determine the likelihood of survival for passengers on the Titanic using Data Science techniques in Python.\n",
        "\n",
        "\n",
        "---\n",
        ">`by Prajakta Singhal`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jF9_zNBVBtDR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sqx10BuH-4-q"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Explore Data\n",
        "# Load data\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# Display first few rows and basic information\n",
        "print(df.head())\n",
        "print(df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "77k8PahwAFdw",
        "outputId": "250e486b-799a-47fa-9b98-7d0e7d4c9aa4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing and Feature Engineering\n",
        "# Handle missing values\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Feature engineering\n",
        "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
        "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
        "\n",
        "# Encode categorical variables\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "# Select features and target variable\n",
        "X = df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "y = df['Survived']\n"
      ],
      "metadata": {
        "id": "lLqBW1ujAKg_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data into Train and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "mwQGUoW2AS1-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and Train the Model\n",
        "# Define preprocessing steps and model pipeline\n",
        "numeric_features = ['Age', 'Fare', 'FamilySize']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features)\n",
        "    ])\n",
        "\n",
        "# Combine preprocessing with classifier\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', RandomForestClassifier(random_state=42))])\n",
        "\n",
        "# Parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200, 300],\n",
        "    'classifier__max_depth': [None, 10, 20, 30],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = grid_search.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l2loIkxEAap7",
        "outputId": "53eb267c-4815-4bd8-b2e1-afae4fbf3c44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best parameters found:  {'classifier__max_depth': None, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
            "Best cross-validation score: 0.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "# Evaluate model\n",
        "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8408098YAedk",
        "outputId": "0bff389d-4d5f-4bfd-e1d4-d5cdff70a376"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.74\n",
            "\n",
            "Confusion Matrix:\n",
            " [[90 15]\n",
            " [32 42]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.86      0.79       105\n",
            "           1       0.74      0.57      0.64        74\n",
            "\n",
            "    accuracy                           0.74       179\n",
            "   macro avg       0.74      0.71      0.72       179\n",
            "weighted avg       0.74      0.74      0.73       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3pWBC6bBlBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}